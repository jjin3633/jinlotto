#!/usr/bin/env python3
"""
ì‚¬ì´íŠ¸ë§µ ë””ë²„ê¹… ë„êµ¬
Google Search Console ì‚¬ì´íŠ¸ë§µ ì˜¤ë¥˜ ì§„ë‹¨
"""

import requests
import xml.etree.ElementTree as ET
from datetime import datetime
import json

def check_sitemap_accessibility():
    """ì‚¬ì´íŠ¸ë§µ ì ‘ê·¼ì„± ìƒì„¸ í™•ì¸"""
    url = "http://stretchinglotto.motiphysio.com/sitemap.xml"
    
    print(f"ğŸ” ì‚¬ì´íŠ¸ë§µ ë””ë²„ê¹…: {url}")
    print("=" * 60)
    
    try:
        # 1. HTTP ìš”ì²­ ìƒì„¸ ì •ë³´
        print("1ï¸âƒ£ HTTP ìš”ì²­ í…ŒìŠ¤íŠ¸...")
        response = requests.get(url, timeout=30, allow_redirects=True)
        
        print(f"   âœ… ìƒíƒœ ì½”ë“œ: {response.status_code}")
        print(f"   âœ… ì‘ë‹µ ì‹œê°„: {response.elapsed.total_seconds():.2f}ì´ˆ")
        print(f"   âœ… ì½˜í…ì¸  íƒ€ì…: {response.headers.get('content-type', 'N/A')}")
        print(f"   âœ… ì½˜í…ì¸  ê¸¸ì´: {len(response.content)} bytes")
        print(f"   âœ… ì„œë²„: {response.headers.get('server', 'N/A')}")
        
        # 2. ë¦¬ë‹¤ì´ë ‰íŠ¸ í™•ì¸
        if response.history:
            print(f"   ğŸ”„ ë¦¬ë‹¤ì´ë ‰íŠ¸ ë°œìƒ: {len(response.history)}íšŒ")
            for i, resp in enumerate(response.history):
                print(f"      {i+1}. {resp.status_code} -> {resp.url}")
        else:
            print("   âœ… ë¦¬ë‹¤ì´ë ‰íŠ¸ ì—†ìŒ")
        
        # 3. XML êµ¬ë¬¸ ê²€ì‚¬
        print("\n2ï¸âƒ£ XML êµ¬ë¬¸ ê²€ì‚¬...")
        try:
            root = ET.fromstring(response.content)
            print("   âœ… XML êµ¬ë¬¸ ì •ìƒ")
            
            # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¸
            if root.tag.endswith('urlset'):
                print("   âœ… urlset íƒœê·¸ í™•ì¸")
            else:
                print(f"   âŒ ì˜ëª»ëœ ë£¨íŠ¸ íƒœê·¸: {root.tag}")
            
            # URL ê°œìˆ˜ í™•ì¸
            urls = root.findall('.//{http://www.sitemaps.org/schemas/sitemap/0.9}url')
            print(f"   âœ… URL ê°œìˆ˜: {len(urls)}ê°œ")
            
            # ê° URL ê²€ì¦
            for i, url_elem in enumerate(urls):
                loc = url_elem.find('{http://www.sitemaps.org/schemas/sitemap/0.9}loc')
                if loc is not None:
                    print(f"      {i+1}. {loc.text}")
                
        except ET.ParseError as e:
            print(f"   âŒ XML êµ¬ë¬¸ ì˜¤ë¥˜: {e}")
            return False
            
        # 4. Google í¬ë¡¤ëŸ¬ ì‹œë®¬ë ˆì´ì…˜
        print("\n3ï¸âƒ£ Google í¬ë¡¤ëŸ¬ ì‹œë®¬ë ˆì´ì…˜...")
        headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'
        }
        
        google_response = requests.get(url, headers=headers, timeout=30)
        print(f"   âœ… Googlebot ì ‘ê·¼: {google_response.status_code}")
        
        if google_response.status_code != response.status_code:
            print(f"   âš ï¸  ì¼ë°˜ ìš”ì²­ê³¼ ë‹¤ë¥¸ ì‘ë‹µ: {response.status_code} vs {google_response.status_code}")
        
        # 5. robots.txt í™•ì¸
        print("\n4ï¸âƒ£ robots.txt í™•ì¸...")
        robots_url = "http://stretchinglotto.motiphysio.com/robots.txt"
        robots_response = requests.get(robots_url, timeout=10)
        
        if robots_response.status_code == 200:
            print("   âœ… robots.txt ì ‘ê·¼ ê°€ëŠ¥")
            if 'sitemap.xml' in robots_response.text.lower():
                print("   âœ… robots.txtì— ì‚¬ì´íŠ¸ë§µ ëª…ì‹œë¨")
            else:
                print("   âš ï¸  robots.txtì— ì‚¬ì´íŠ¸ë§µ ë¯¸ëª…ì‹œ")
        else:
            print(f"   âŒ robots.txt ì ‘ê·¼ ë¶ˆê°€: {robots_response.status_code}")
        
        # 6. ì¢…í•© ì§„ë‹¨
        print("\n" + "=" * 60)
        print("ğŸ“Š ì¢…í•© ì§„ë‹¨ ê²°ê³¼")
        print("=" * 60)
        
        issues = []
        
        if response.status_code != 200:
            issues.append(f"HTTP ìƒíƒœ ì½”ë“œ ì˜¤ë¥˜: {response.status_code}")
        
        if response.elapsed.total_seconds() > 10:
            issues.append(f"ì‘ë‹µ ì‹œê°„ ì§€ì—°: {response.elapsed.total_seconds():.2f}ì´ˆ")
        
        content_type = response.headers.get('content-type', '')
        if 'xml' not in content_type.lower():
            issues.append(f"ì˜ëª»ëœ Content-Type: {content_type}")
        
        if len(response.content) < 100:
            issues.append("ì‚¬ì´íŠ¸ë§µ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ")
        
        if issues:
            print("âŒ ë°œê²¬ëœ ë¬¸ì œì :")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print("âœ… ëª¨ë“  ê²€ì‚¬ í†µê³¼!")
        
        # 7. í•´ê²° ë°©ì•ˆ ì œì‹œ
        if issues:
            print("\nğŸ’¡ í•´ê²° ë°©ì•ˆ:")
            if response.status_code != 200:
                print("   1. ì„œë²„ ì„¤ì • í™•ì¸ ë° ì‚¬ì´íŠ¸ë§µ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸")
            if response.elapsed.total_seconds() > 10:
                print("   2. ì„œë²„ ì„±ëŠ¥ ìµœì í™” ë˜ëŠ” CDN ì‚¬ìš© ê³ ë ¤")
            if 'xml' not in content_type.lower():
                print("   3. ì›¹ì„œë²„ì—ì„œ .xml íŒŒì¼ì˜ MIME íƒ€ì…ì„ 'application/xml' ë˜ëŠ” 'text/xml'ë¡œ ì„¤ì •")
        
        return len(issues) == 0
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: {e}")
        return False

def generate_improved_sitemap():
    """ê°œì„ ëœ ì‚¬ì´íŠ¸ë§µ ìƒì„±"""
    print("\nğŸ”§ ê°œì„ ëœ ì‚¬ì´íŠ¸ë§µ ìƒì„±...")
    
    sitemap_content = '''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
        xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9
        http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">
  <url>
    <loc>http://stretchinglotto.motiphysio.com/</loc>
    <lastmod>{}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>1.0</priority>
  </url>
</urlset>'''.format(datetime.now().strftime('%Y-%m-%d'))
    
    # í”„ë¡ íŠ¸ì—”ë“œì™€ ë°±ì—”ë“œ ëª¨ë‘ì— ì €ì¥
    paths = [
        'frontend/sitemap.xml',
        'backend/static/sitemap.xml'
    ]
    
    for path in paths:
        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(sitemap_content)
            print(f"   âœ… {path} ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        except Exception as e:
            print(f"   âŒ {path} ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def main():
    print("ğŸš¨ Google Search Console ì‚¬ì´íŠ¸ë§µ ì˜¤ë¥˜ í•´ê²° ë„êµ¬")
    print(f"â° ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # í˜„ì¬ ì‚¬ì´íŠ¸ë§µ ìƒíƒœ í™•ì¸
    is_ok = check_sitemap_accessibility()
    
    if not is_ok:
        print("\nğŸ”§ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê°œì„ ëœ ì‚¬ì´íŠ¸ë§µì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n)")
        # ìë™ìœ¼ë¡œ ìƒì„±
        generate_improved_sitemap()
        
        print("\nğŸ“‹ ì¶”ê°€ í•´ê²° ë°©ì•ˆ:")
        print("1. ì›¹ì„œë²„ ì„¤ì •ì—ì„œ .xml íŒŒì¼ì˜ MIME íƒ€ì… í™•ì¸")
        print("2. Google Search Consoleì—ì„œ ê¸°ì¡´ ì‚¬ì´íŠ¸ë§µ ì‚­ì œ í›„ ì¬ì œì¶œ")
        print("3. 24-48ì‹œê°„ í›„ ë‹¤ì‹œ í™•ì¸")
    
    print("\nâœ… ì§„ë‹¨ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
